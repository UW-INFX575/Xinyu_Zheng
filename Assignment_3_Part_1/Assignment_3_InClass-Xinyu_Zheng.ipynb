{
 "metadata": {
  "name": "",
  "signature": "sha256:d3e7019a7bff20d26c3165557e088b9274a268ba3d3193dcde746ae772b3f40b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import libraries for processing\n",
      "import nltk\n",
      "import unicodedata\n",
      "import string\n",
      "from nltk import stem\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "from nltk import bigrams\n",
      "from nltk import trigrams\n",
      "\n",
      "# initialize stop set, single letters, special characters\n",
      "stopset = set(stopwords.words('english'))\n",
      "\n",
      "# initialize array to save result, file names, and new files to save result\n",
      "file_name = 'abstracts.txt'\n",
      "stopwords = [\"all\",\"just\",\"being\",\"over\",\"both\",\"through\",\"yourselves\",\"its\",\"before\",\"herself\",\"had\",\"should\",\"to\",\"only\",\"under\",\"ours\",\"has\",\"do\",\"them\",\"his\",\"very\",\"they\",\"not\",\"during\",\"now\",\"him\",\"nor\",\"did\",\"this\",\"she\",\"each\",\"further\",\"where\",\"few\",\"because\",\"doing\",\"some\",\"are\",\"our\",\"ourselves\",\"out\",\"what\",\"for\",\"while\",\"does\",\"above\",\"between\",\"t\",\"be\",\"we\",\"who\",\"were\",\"here\",\"hers\",\"by\",\"on\",\"about\",\"of\",\"against\",\"s\",\"or\",\"own\",\"into\",\"yourself\",\"down\",\"your\",\"from\",\"her\",\"their\",\"there\",\"been\",\"whom\",\"too\",\"themselves\",\"was\",\"until\",\"more\",\"himself\",\"that\",\"but\",\"don\",\"with\",\"than\",\"those\",\"he\",\"me\",\"myself\",\"these\",\"up\",\"will\",\"below\",\"can\",\"theirs\",\"my\",\"and\",\"then\",\"is\",\"am\",\"it\",\"an\",\"as\",\"itself\",\"at\",\"have\",\"in\",\"any\",\"if\",\"again\",\"no\",\"when\",\"same\",\"how\",\"other\",\"which\",\"you\",\"after\",\"most\",\"such\",\"why\",\"a\",\"off\",\"i\",\"yours\",\"so\",\"the\",\"having\",\"once\"]\n",
      "new_abstracts = []\n",
      "\n",
      "def split_docs(a_file):\n",
      "    count_docs = 0\n",
      "    with open(a_file, 'r') as text_file:\n",
      "        text = text_file.read()\n",
      "        text = text.splitlines()        \n",
      "        for w in text:            \n",
      "            if (w[-4:] != 'null'):\n",
      "                new_abstracts.append(w)\n",
      "                count_docs = count_docs + 1       \n",
      "    return count\n",
      "\n",
      "split_docs(file_name)\n",
      "\n",
      "import re\n",
      "group1 = []\n",
      "group2 = []\n",
      "group3 = []\n",
      "\n",
      "def split_groups(a_file):\n",
      "    for doc in new_abstracts:\n",
      "        if ((re.search('2408678(.*)', doc)) or (re.search('2459379(.*)', doc)) or (re.search('2409177(.*)', doc)) or (re.search('2461605(.*)', doc)) or (re.search('2458768(.*)', doc)) or (re.search('1745369(.*)', doc)) or (re.search('2825234(.*)', doc)) or (re.search('2096934(.*)', doc)) or (re.search('2459010(.*)', doc)) or (re.search('1942661(.*)', doc))):\n",
      "            group1.append(doc)\n",
      "        if ((re.search('67376(.*)', doc)) or (re.search('66230(.*)', doc)) or (re.search('70083(.*)', doc)) or (re.search('1604132(.*)', doc)) or (re.search('1700278(.*)', doc)) or (re.search('1603658(.*)', doc)) or (re.search('9298(.*)', doc)) or (re.search('61400(.*)', doc)) or (re.search('23751(.*)', doc)) or (re.search('68319(.*)', doc))):\n",
      "            group2.append(doc)\n",
      "        if ((re.search('2626876(.*)', doc)) or (re.search('1912934(.*)', doc)) or (re.search('2228949(.*)', doc)) or (re.search('724810(.*)', doc)) or (re.search('1912352(.*)', doc)) or (re.search('2977928(.*)', doc)) or (re.search('1809766(.*)', doc)) or (re.search('1914185(.*)', doc)) or (re.search('1913738(.*)', doc)) or (re.search('1831029(.*)', doc))):\n",
      "            group3.append(doc)\n",
      "    return True\n",
      "\n",
      "split_groups(file_name)\n",
      "\n",
      "def remove_docnum(a_group):\n",
      "    cleaned_group = []\n",
      "    cleaned_docid = []\n",
      "    for doc in a_group:\n",
      "        doc = doc.split('\\t')\n",
      "        cleaned_group.append(doc[1])\n",
      "        cleaned_docid.append(doc[0])\n",
      "    return cleaned_group,cleaned_docid\n",
      "\n",
      "group1_doc = []\n",
      "group1_docid = []\n",
      "group1_doc,group1_docid = remove_docnum(group1)\n",
      "\n",
      "group2_doc = []\n",
      "group2_docid = []\n",
      "group2_doc,group2_docid = remove_docnum(group2)\n",
      "\n",
      "group3_doc = []\n",
      "group3_docid = []\n",
      "group3_doc,group3_docid = remove_docnum(group3)\n",
      "\n",
      "def clean_words(a_group):\n",
      "    group_words = []\n",
      "    for d in a_group:\n",
      "        tokens=word_tokenize(str(d)) \n",
      "        for w in tokens:\n",
      "            if (w not in stopwords):\n",
      "                group_words.append(w)\n",
      "    return group_words\n",
      "\n",
      "group1_words = clean_words(group1_doc)\n",
      "group2_words = clean_words(group2_doc)\n",
      "group3_words = clean_words(group3_doc)\n",
      "\n",
      "corpus12_words = []\n",
      "for w1 in group1_words:\n",
      "    corpus12_words.append(w1)\n",
      "for w2 in group2_words:\n",
      "    corpus12_words.append(w2)\n",
      "\n",
      "corpus13_words = []\n",
      "for w1 in group1_words:\n",
      "    corpus13_words.append(w1)\n",
      "for w3 in group3_words:\n",
      "    corpus13_words.append(w3)\n",
      "\n",
      "corpus23_words = []\n",
      "for w2 in group2_words:\n",
      "    corpus23_words.append(w2)\n",
      "for w3 in group3_words:\n",
      "    corpus23_words.append(w3)\n",
      "# print corpus_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define a function to create vocab for an array\n",
      "def generate_vocab(cleaned_array):\n",
      "    seen = set()\n",
      "    result = []\n",
      "    for item in cleaned_array:\n",
      "        if item not in seen:\n",
      "            seen.add(item)\n",
      "            result.append(item)\n",
      "    return result\n",
      "\n",
      "group1_vocab = generate_vocab(group1_words)\n",
      "group2_vocab = generate_vocab(group2_words)\n",
      "group3_vocab = generate_vocab(group3_words)\n",
      "corpus12_vocab = generate_vocab(corpus12_words)\n",
      "corpus13_vocab = generate_vocab(corpus13_words)\n",
      "corpus23_vocab = generate_vocab(corpus23_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "group1_wordfreq = Counter(group1_words).most_common()\n",
      "group2_wordfreq = Counter(group2_words).most_common()\n",
      "group3_wordfreq = Counter(group3_words).most_common()\n",
      "\n",
      "corpus12_wordfreq = Counter(corpus12_words).most_common()\n",
      "corpus13_wordfreq = Counter(corpus13_words).most_common()\n",
      "corpus23_wordfreq = Counter(corpus23_words).most_common()\n",
      "\n",
      "# count word occurrance probabilities for each toy datasets, group one, group two, and whole corpus\n",
      "def count_wordprob(a_wordfreq):\n",
      "    freq = []\n",
      "    word = []\n",
      "    for k in a_wordfreq:\n",
      "        freq.append(k[1])\n",
      "        word.append(k[0])\n",
      "\n",
      "    total_sum = 0\n",
      "    for f in freq:\n",
      "        total_sum += f\n",
      "\n",
      "    prob = []\n",
      "    for p in freq:\n",
      "        prob.append(round(p*1.0/total_sum,5))\n",
      "\n",
      "    return prob,word\n",
      "\n",
      "group1_prob,group1_word = count_wordprob(group1_wordfreq)\n",
      "group2_prob,group2_word = count_wordprob(group2_wordfreq)\n",
      "group3_prob,group3_word = count_wordprob(group3_wordfreq)\n",
      "corpus12_prob,corpus12_word = count_wordprob(corpus12_wordfreq)\n",
      "corpus13_prob,corpus13_word = count_wordprob(corpus13_wordfreq)\n",
      "corpus23_prob,corpus23_word = count_wordprob(corpus23_wordfreq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "# calculate H(xi) for group one\n",
      "def get_H(group_prob):\n",
      "    log_sum_group = 0\n",
      "    for i in group_prob:\n",
      "        tmp_log = math.log(i,2)\n",
      "        log_sum_group += i * tmp_log\n",
      "    H_group = 0 - log_sum_group\n",
      "    return H_group\n",
      "\n",
      "H1 = get_H(group1_prob)\n",
      "H2 = get_H(group2_prob)\n",
      "H3 = get_H(group3_prob)\n",
      "\n",
      "print H1\n",
      "print H2\n",
      "print H3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8.68073089592\n",
        "8.27870061078\n",
        "7.39901075083\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate Q12\n",
      "import math\n",
      "\n",
      "def get_Qij(groupi_word,groupj_word,groupij_word,groupi_prob,groupj_prob,groupij_prob):\n",
      "    tmp_Qij = 0\n",
      "    for i in range(len(groupi_word)):\n",
      "        wi = groupi_word[i]\n",
      "\n",
      "        if wi in groupj_word:\n",
      "            ind = groupj_word.index(wi)\n",
      "            pj = groupj_prob[ind]\n",
      "            pi = groupi_prob[i]\n",
      "        else:\n",
      "            alpha = 0.01\n",
      "            ind = groupij_word.index(wi)\n",
      "            sj = groupij_prob[ind]\n",
      "            pj = alpha * sj\n",
      "            pi = (1-alpha)*groupi_prob[i]+alpha*sj\n",
      "\n",
      "        tmp_Qij += pi * math.log(pj,2)\n",
      "    Q_ij = 0 - tmp_Qij\n",
      "    return Q_ij\n",
      "\n",
      "Q_12 = get_Qij(group1_word,group2_word,corpus12_word,group1_prob,group2_prob,corpus12_prob)\n",
      "Q_21 = get_Qij(group2_word,group1_word,corpus12_word,group2_prob,group1_prob,corpus12_prob)\n",
      "Q_13 = get_Qij(group1_word,group3_word,corpus13_word,group1_prob,group3_prob,corpus13_prob)\n",
      "Q_31 = get_Qij(group3_word,group1_word,corpus13_word,group3_prob,group1_prob,corpus13_prob)\n",
      "Q_23 = get_Qij(group2_word,group3_word,corpus23_word,group2_prob,group3_prob,corpus23_prob)\n",
      "Q_32 = get_Qij(group3_word,group2_word,corpus23_word,group3_prob,group2_prob,corpus23_prob)\n",
      "\n",
      "print Q_12\n",
      "print Q_21\n",
      "print Q_13\n",
      "print Q_31\n",
      "print Q_23\n",
      "print Q_32"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15.3475139953\n",
        "15.1602864746\n",
        "15.0025219394\n",
        "14.3214812662\n",
        "14.8722782133\n",
        "14.6565821079\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate E12\n",
      "E_12 = H1 / Q_12\n",
      "print 'E_12:', E_12\n",
      "\n",
      "# calculate E21\n",
      "E_21 = H2 / Q_21\n",
      "print 'E_21:', E_21\n",
      "\n",
      "# calculate E12\n",
      "E_13 = H1 / Q_13\n",
      "print 'E_13:', E_13\n",
      "\n",
      "# calculate E21\n",
      "E_31 = H3 / Q_31\n",
      "print 'E_31:', E_31\n",
      "\n",
      "# calculate E12\n",
      "E_23 = H2 / Q_23\n",
      "print 'E_23:', E_23\n",
      "\n",
      "# calculate E21\n",
      "E_32 = H3 / Q_32\n",
      "print 'E_32:', E_32"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "E_12: 0.56561153152\n",
        "E_21: 0.546078111695\n",
        "E_13: 0.578618110406\n",
        "E_31: 0.51663725374\n",
        "E_23: 0.556653156434\n",
        "E_32: 0.504825115184\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate C12\n",
      "C_12 = 1 - E_12\n",
      "print 'C_12:', C_12\n",
      "\n",
      "# calculate C21\n",
      "C_21 = 1 - E_21\n",
      "print 'C_21:', C_21\n",
      "\n",
      "# calculate C12\n",
      "C_13 = 1 - E_13\n",
      "print 'C_13:', C_13\n",
      "\n",
      "# calculate C21\n",
      "C_31 = 1 - E_31\n",
      "print 'C_31:', C_31\n",
      "\n",
      "# calculate C12\n",
      "C_23 = 1 - E_23\n",
      "print 'C_23:', C_23\n",
      "\n",
      "# calculate C21\n",
      "C_32 = 1 - E_32\n",
      "print 'C_32:', C_32\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C_12: 0.43438846848\n",
        "C_21: 0.453921888305\n",
        "C_13: 0.421381889594\n",
        "C_31: 0.48336274626\n",
        "C_23: 0.443346843566\n",
        "C_32: 0.495174884816\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate C1\n",
      "C_1 = (C_12 + C_13)/2\n",
      "print 'C_1:', C_1\n",
      "\n",
      "# calculate C2\n",
      "C_2 = (C_21 + C_23)/2\n",
      "print 'C_2:', C_2\n",
      "\n",
      "# calculate C3\n",
      "C_3 = (C_31 + C_32)/2\n",
      "print 'C_3:', C_3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C_1: 0.427885179037\n",
        "C_2: 0.448634365935\n",
        "C_3: 0.489268815538\n"
       ]
      }
     ],
     "prompt_number": 84
    }
   ],
   "metadata": {}
  }
 ]
}